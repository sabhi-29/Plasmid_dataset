{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53345f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will make smart scrapper using selenium in this notebook\n",
    "# Along with the associated functions required.\n",
    "\n",
    "# The purpose of this python file is to serve as library of functions for our main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "791f8b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing neccesary libraries\n",
    "from selenium import webdriver \n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import Entrez, SeqIO\n",
    "from urllib.request import urlretrieve\n",
    "import requests\n",
    "from colorama import Fore\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468aa2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if there is captcha present on the called url\n",
    "def check_captcha(html_soup):\n",
    "    soup_as_str = str(html_soup)\n",
    "    \n",
    "    if 'captcha' in soup_as_str:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# Making the function to generate the url given a pubmed id\n",
    "\n",
    "def get_paper_url(pubmed_id):\n",
    "    Entrez.email = \"your_email@example.com\"  # Provide your email address\n",
    "\n",
    "    # Fetch the summary information for the specified PubMed ID\n",
    "    handle = Entrez.esummary(db=\"pubmed\", id=pubmed_id)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "\n",
    "    # Extract relevant information such as title and authors\n",
    "    paper_info = {\n",
    "        \"title\": record[0][\"Title\"],\n",
    "        \"authors\": record[0][\"AuthorList\"],\n",
    "    }\n",
    "    \n",
    "    # Now generating the url for google scholar \n",
    "    query = f\"{paper_info[title]} {', '.join(paper_info[authors])}\"\n",
    "\n",
    "    url = f\"https://scholar.google.com/scholar?q={'+'.join(query.split())}\"\n",
    "    \n",
    "    return url\n",
    "\n",
    "    \n",
    "# Making function to hold our program execution for upto one minute so that we \n",
    "# get blocked by google scholar less frequently\n",
    "\n",
    "def pause_for_one_minute():\n",
    "    random_time = random.randint(30,60)\n",
    "    print(f\"Pausing for {random_time} seconds...\")\n",
    "    time.sleep(random_time)\n",
    "    print(\"Resuming normal execution.\")    \n",
    "\n",
    "# Function to call Selenium driver and scrape the citations of the paper\n",
    "\n",
    "def scrape(url):\n",
    "    # Making driver using Firefox\n",
    "    driver = webdriver.Firefox()\n",
    "    \n",
    "    # Opening the window\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Inspecting the page to see if their is a captcha\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    # Using beautiful soup to parse the page\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "    captcha_present = check_captcha(soup)\n",
    "    \n",
    "    if captcha_present == True:\n",
    "        # Now we need to tell the user to solve the captcha\n",
    "        user_input = input(\"Please solve the captcha manually and press enter after you do so:\")\n",
    "        \n",
    "        # After the user presses enter we will take a timeout \n",
    "        # after that we will again inspect the page and get the citations\n",
    "        pause_for_one_minute()\n",
    "        \n",
    "        # Now we inspect the page\n",
    "        page_source = driver.page_source\n",
    "        \n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        \n",
    "        # closing the driver and returning the number of citations\n",
    "        driver.quit()\n",
    "        \n",
    "        return soup[soup.find(\"Cited by\"):].split()[2][:-4]\n",
    "    \n",
    "    else:\n",
    "        # Incase we don't get a captcha to solve we directly extract the citations and return them\n",
    "        # first we close the driver\n",
    "        driver.quit()\n",
    "        return soup[soup.find(\"Cited by\"):].split()[2][:-4]\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
