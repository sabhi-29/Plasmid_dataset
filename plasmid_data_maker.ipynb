{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "222b1307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping the plasmid data extractor function separately\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c20a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making function to create folders to store plasmid details for various hits\n",
    "# separately, if the plasmid folder has already been created the function returns us the path to the folder\n",
    "\n",
    "def create_new_folder(folder_name):\n",
    "    # Check if the folder already exists\n",
    "    if not os.path.exists(folder_name):\n",
    "        # The path does not exist so we will be making a new folder\n",
    "        # Create the folder\n",
    "        try:\n",
    "            os.mkdir(folder_name)\n",
    "            return os.path.abspath(folder_name)\n",
    "        except:\n",
    "            # If for some reason we are unable to create a folder due to the name of the plasmid \n",
    "            # we will create a folder with a different name and store the hit result there\n",
    "            if not os.path.exists(f\"Miscellaneous_{folder_name}_end\"):\n",
    "                folder_name = f\"Miscellaneous_{folder_name}_end\"\n",
    "                os.mkdir(folder_name)\n",
    "                return os.path.abspath(folder_name)\n",
    "            else:\n",
    "#                 print(f\"Folder weird_name already exists.\")\n",
    "                return os.path.abspath(f\"Miscellaneous_{folder_name}_end\")\n",
    "    else:\n",
    "#         print(f\"Folder '{folder_name}' already exists.\")\n",
    "        return os.path.abspath(folder_name)\n",
    "\n",
    "\n",
    "\n",
    "############ BETA VERSION OF THE ABOVE FUNCTION (WORK IN PROGRESS)################################\n",
    "\n",
    "# Writing the function that will pull all the plasmid hits with updated criteria\n",
    "# Set up a way to find the hits that contain the journalllll of publication and the author, webscrap to find citations\n",
    "# add the hit to list only if citations > 10\n",
    "\n",
    "# We also keep a track of which plasmids and accession number pass both of our filters\n",
    "\n",
    "def plasmid_data_improved(plasmid_name_1, plasmid_email_id, filter_pass_list):\n",
    "\n",
    "############## REMEMBER TO UNCOMMENT THIS PORTION WHEN RUNNING FINALLY ###################################\n",
    "    # Making the folder for the plamsmid hits and storing it's path\n",
    "    folder_name = plasmid_name_1\n",
    "    if '.' in folder_name:\n",
    "        folder_name = folder_name.split('.')\n",
    "        temp_str = ''\n",
    "        for sub_str in folder_name:\n",
    "            temp_str += sub_str\n",
    "            temp_str += '_'\n",
    "#         folder_name = temp_str\n",
    "    else:\n",
    "        temp_str = folder_name\n",
    "    path = create_new_folder(temp_str)\n",
    "    print(f\"Folder made for {folder_name} as {temp_str}\")\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "    # Setting up our query and accessing Entrez\n",
    "    query = f\"Plasmid+{plasmid_name_1}\"\n",
    "    email = plasmid_email_id\n",
    "    Entrez.email = email\n",
    "\n",
    "    # Searching GenBank now\n",
    "    handle = Entrez.esearch(db = 'nucleotide', term = query, retmax = 100)\n",
    "    record_id = Entrez.read(handle)['IdList']\n",
    "    handle.close()\n",
    "    # print(record_id)\n",
    "    # Now storing the data we got in form of a dataframe\n",
    "    # First making the dictionary to store the data\n",
    "\n",
    "    plasmid_data = {\"Accession No.\": [], 'Organism': [], 'Topology': [], 'Plasmid': [], 'Nucleotide Sequence': [],\n",
    "                  'Locus Tag': [], 'Gene Name': [], 'Gene Location': [], 'Gene Product': [], 'Gene Sequence': []}\n",
    "\n",
    "    # Going through each record we got from the entrez esearch\n",
    "    for records in record_id:\n",
    "        # Extracting the genbank record for the id\n",
    "        genbank_record = Entrez.efetch(db = 'nucleotide', id = records, rettype = 'gb', retmode = 'text')\n",
    "        # Reading the record\n",
    "        gb_record = SeqIO.read(genbank_record, 'genbank')\n",
    "        # For each record that we retrieve we will perform some filtering to get the nucleotide sequence of our \n",
    "        # interest - seeing if the decription contains the plasmid name of interest and if it is complete or not\n",
    "        \n",
    "        # First order filtering (FILTER 1) - the record is non-empty and contains the keyword 'complete sequence'\n",
    "        # along with the plasmid name\n",
    "        if (len(gb_record.id) != 0 and len(gb_record.description) != 0) and len(gb_record.seq) != 0:\n",
    "            \n",
    "            # We will check if the sequence is of our plasmid of interest and complete or not, if yes then we proceed\n",
    "            # Extracting Accession Number and description\n",
    "            \n",
    "            \n",
    "            accession = [str(gb_record.annotations['accessions'][0])]\n",
    "            description = gb_record.description\n",
    "\n",
    "            ##### DEBUGGING PRINT STATEMENT ##############################\n",
    "            print(f\"Current hit: {plasmid_name_1} :- {description}\")\n",
    "            ################################################################\n",
    "\n",
    "\n",
    "            # We are going to add the record only if it is complete and has the plasmid of interest\n",
    "            if plasmid_name_1.lower() in description.lower() and ('complete sequence' in description.lower() or 'complete genome' in description.lower()):\n",
    "                \n",
    "                ##### DEBUGGING PRINT STATEMENT ##############################\n",
    "#                 print(gb_record.annotations.get(\"references\")[0].pubmed_id)\n",
    "                ################################################################\n",
    "                \n",
    "                # SECOND ORDER FILTERING (FILTER 2.1) - the record must have a PubMed ID\n",
    "                if not gb_record.annotations.get(\"references\")[0].pubmed_id:\n",
    "                    continue\n",
    "                # Now we are sure that the record contains the plasmid name, is complete and has a pubmed id\n",
    "                \n",
    "                \n",
    "                # SECOND ORDER FILTERING (FILTER 2.2) - the record must have more than 10 citations\n",
    "                \n",
    "                # Storing the pubmed id\n",
    "                paper_pubmed_id = gb_record.annotations.get(\"references\")[0].pubmed_id\n",
    "                # Getting the paper title and the authors using previously defined function\n",
    "                paper_info = get_paper_info(paper_pubmed_id)\n",
    "                paper_title = paper_info['title']\n",
    "                paper_authors = paper_info['authors']\n",
    "                print(f\"{paper_title} {paper_authors}\")\n",
    "                # Now getting the number of citations of the paper\n",
    "                paper_citations = int(get_citations_count_from_google_scholar(paper_title, paper_authors))\n",
    "                # Checking if the citations > 10\n",
    "#                 print(f\"{paper_title} {paper_authors}\")\n",
    "                print(paper_citations)\n",
    "                \n",
    "                if paper_citations < 10:\n",
    "                    continue\n",
    "                \n",
    "#                 print(f\"Current hit is published in {paper_title} by {', '.join(paper_authors)} and has {paper_citations} citations.\")\n",
    "                \n",
    "                \n",
    "                # Pausing the execution for a minute to not cross our daily query limit using API or being detected\n",
    "                # by google scholar bot for querying too much\n",
    "                pause_for_one_minute()\n",
    "            \n",
    "                \n",
    "                # Now we continue, since we successfully know that the nucleotide sequence associated with the pubmed id\n",
    "                # has > 10 citations as well, we will keep a record of the plasmid name and accession number that\n",
    "                # surpass both the set filters. We will use it when using Abricate and Plasmid Finder\n",
    "                \n",
    "                if str(description.split(\"plasmid \")[-1].split(\",\")[0]) in filter_pass_list.keys():\n",
    "                    filter_pass_list[str(description.split(\"plasmid \")[-1].split(\",\")[0])].append(accession[0])\n",
    "                else:\n",
    "                    filter_pass_list[str(description.split(\"plasmid \")[-1].split(\",\")[0])] = []\n",
    "                \n",
    "                \n",
    "                # Now we know that the sequence has passed FILTER 1 and FILTER 2 we proceed making a dataframe. \n",
    "                organism = [str(gb_record.annotations[\"source\"])]\n",
    "                plasmid_name = [str(description.split(\"plasmid \")[-1].split(\",\")[0])]\n",
    "                locus_tag = []\n",
    "                topology = [str(gb_record.annotations['topology'])]\n",
    "                gene_prdt = []\n",
    "                gene_seq = []\n",
    "                location = []\n",
    "                gene_name = []\n",
    "\n",
    "                ###########################################\n",
    "                # Getting nucleotide sequence\n",
    "                handle = Entrez.efetch(db=\"nucleotide\", id=accession[0], rettype=\"fasta\", retmode=\"text\")\n",
    "                fasta_sequence = handle.read()\n",
    "                handle.close()\n",
    "                fasta_seq_split = [x for x in fasta_sequence.split()]\n",
    "                # To get the nucleotide sequence we get everything after 'complete sequence'\n",
    "                # Finding complete sequence\n",
    "                i = 1\n",
    "                while fasta_seq_split[i-1] != 'sequence':        \n",
    "                    i += 1\n",
    "                # Now we are at the start of the nucleotide sequence we store all that follows\n",
    "                nuc_seq = ''\n",
    "                while i < len(fasta_seq_split):\n",
    "                    nuc_seq += fasta_seq_split[i]\n",
    "                    i += 1\n",
    "                # print(nuc_seq)\n",
    "                nucleotide_seq = [str(nuc_seq)]\n",
    "                ###########################################################\n",
    "\n",
    "                # Now we will access the record and store the bacteria name, accession number,\n",
    "                # topology, plasmid, nucleotide sequence, locus tag for each gene with gene name present\n",
    "                # and store their respective names, location, gene product thier sequence\n",
    "\n",
    "                \n",
    "                # First we access the features and get all the data of interest\n",
    "                for features in gb_record.features:\n",
    "                    if features.type == 'CDS':\n",
    "                        # We first see if the qualifiers contains gene, if not then we skip that gene\n",
    "                        if 'gene' in features.qualifiers.keys():\n",
    "                            # In case translation, locus tag, gene product is missing then we simply leave that cell empty\n",
    "                            # print(features.qualifiers.keys())\n",
    "                            # Storing the gene name first\n",
    "                            gene_name.append(str(features.qualifiers.get('gene')[0]))\n",
    "                            # Now storing other data - locus tag, gene product, translation, sequence\n",
    "                            if 'locus_tag' in features.qualifiers.keys():\n",
    "                                locus_tag.append(str(features.qualifiers.get('locus_tag')[0]))\n",
    "                            else:\n",
    "                                locus_tag.append('NaN')\n",
    "                            if 'product' in features.qualifiers.keys():\n",
    "                                gene_prdt.append(str(features.qualifiers['product'][0]))\n",
    "                            else:\n",
    "                                gene_prdt.append('NaN')\n",
    "                            if 'translation' in features.qualifiers.keys():\n",
    "                                gene_seq.append(str(features.qualifiers['translation'][0]))\n",
    "                            else:\n",
    "                                gene_seq.append('NaN')\n",
    "                        # Storing the location of the gene on the nucleotide sequenceeeeeeee\n",
    "                        if features.type == 'gene':\n",
    "                            location.append(str(features.location))\n",
    "\n",
    "                # We will make the dataframe and store it only if all the columns are of the same length\n",
    "                # print(len(locus_tag), len(locus_tag))\n",
    "                if (len(locus_tag) == len(location) and len(locus_tag)!= 0):\n",
    "                    plasmid_data[\"Accession No.\"] = accession*len(locus_tag)\n",
    "                    plasmid_data[\"Organism\"] = organism*len(locus_tag)\n",
    "                    plasmid_data[\"Topology\"] = topology*len(locus_tag)\n",
    "                    plasmid_data[\"Plasmid\"] = plasmid_name*len(locus_tag)\n",
    "                    plasmid_data[\"Nucleotide Sequence\"] = nucleotide_seq*len(locus_tag)\n",
    "                    plasmid_data[\"Locus Tag\"] = locus_tag\n",
    "                    plasmid_data[\"Gene Length\"] = [len(x) for x in gene_seq if x != 'NaN']\n",
    "                    plasmid_data[\"Gene Name\"] = gene_name\n",
    "                    plasmid_data[\"Gene Sequence\"] = gene_seq\n",
    "                    plasmid_data[\"Gene Product\"] = gene_prdt\n",
    "                    plasmid_data['Gene Location'] = location\n",
    "                \n",
    "                \n",
    "                # print(plasmid_data)\n",
    "                # Making the dataframe\n",
    "                dataframe = pd.DataFrame(plasmid_data)\n",
    "                \n",
    "                # Now we will use abricate to get the identified resistance to some (or all) genes \n",
    "                # as well present on the sequence\n",
    "                \n",
    "                # First saving the nucleotide sequence of the record as fasta file\n",
    "                fasta_path = f\"{accession[0]}_{plasmid_name[0]}.fa\"\n",
    "                with open(fasta_path, 'w') as file:\n",
    "                    file.write(fasta_sequence)\n",
    "                # Now using abricate on this saved file\n",
    "                input_file_fas = fasta_path\n",
    "                abricate_cmd = f'abricate {input_file_fas} --csv > {input_file_fas}_1.csv'\n",
    "                result = subprocess.check_output(abricate_cmd, shell = True, universal_newlines = True)\n",
    "                abr_df = pd.read_csv(f'{input_file_fas}_1.csv')\n",
    "                abr_df.head()\n",
    "                \n",
    "                \n",
    "                # Saving the dataframe\n",
    "                dataframe.to_excel(f'{path}/{accession[0]}_{plasmid_name[0]}_data.xlsx', index = False)\n",
    "                print(f\"DataFrame made for {plasmid_name[0]} at /{accession[0]}\")\n",
    "                \n",
    "#                 dataframe.head()\n",
    "#             else:\n",
    "#                 print(\"The hit does not pass the filter\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
